{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img101_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img102_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img103_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img107_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img107_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img107_crop_2.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img107_crop_3.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img109_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img109_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img109_crop_2.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img112_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img113_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img115_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img115_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img115_crop_2.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img115_crop_3.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img115_crop_4.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img115_crop_5.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img122_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img122_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img123_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img123_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img127_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img127_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img128_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img128_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img128_crop_2.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img129_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img129_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img129_crop_2.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img129_crop_3.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img12_crop_2.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img130_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img132_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img135_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img136_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img136_crop_1.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img136_crop_2.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img136_crop_3.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img137_crop_0.jpg\n",
      "Processed image saved to postprocessing_datasettttt_degree0\\degree_1\\img137_crop_1.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m input_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmallerrefined\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     68\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostprocessing_datasettttt_degree0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 69\u001b[0m \u001b[43mpreprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 65\u001b[0m, in \u001b[0;36mpreprocess_dataset\u001b[1;34m(input_dir, output_dir)\u001b[0m\n\u001b[0;32m     63\u001b[0m relative_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrelpath(input_path, input_dir)\n\u001b[0;32m     64\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, relative_path)\n\u001b[1;32m---> 65\u001b[0m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path, output_path, standard_size, d, sigma_color, sigma_space)\u001b[0m\n\u001b[0;32m     45\u001b[0m lab_clahe \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmerge((L_clahe, A, B))\n\u001b[0;32m     46\u001b[0m enhanced_bgr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(lab_clahe, cv2\u001b[38;5;241m.\u001b[39mCOLOR_LAB2BGR)\n\u001b[1;32m---> 47\u001b[0m preprocessed_image \u001b[38;5;241m=\u001b[39m \u001b[43mmy_bilateral_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43menhanced_bgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(output_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     50\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(output_path, preprocessed_image)\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36mmy_bilateral_filter\u001b[1;34m(image, d, sigma_color, sigma_space)\u001b[0m\n\u001b[0;32m     27\u001b[0m         weights \u001b[38;5;241m=\u001b[39m spatial_kernel \u001b[38;5;241m*\u001b[39m range_kernel\n\u001b[0;32m     28\u001b[0m         weights_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(weights)\n\u001b[1;32m---> 29\u001b[0m         filtered[i, j, :] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m weights_sum\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filtered\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "def my_bilateral_filter(image, d, sigma_color, sigma_space):\n",
    "    \"\"\"Apply a custom bilateral filter to the image.\"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    H, W, C = image.shape\n",
    "    half = d // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(image, half, half, half, half, cv2.BORDER_REFLECT)\n",
    "    filtered = np.zeros_like(image)\n",
    "\n",
    "    xs = np.arange(-half, half+1)\n",
    "    ys = np.arange(-half, half+1)\n",
    "    X, Y = np.meshgrid(xs, ys)\n",
    "    spatial_kernel = np.exp(-((X**2 + Y**2) / (2 * sigma_space * sigma_space)))\n",
    "\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            region = padded[i:i+d, j:j+d, :]\n",
    "            center_pixel = padded[i+half, j+half, :]\n",
    "            diff = region - center_pixel\n",
    "            color_distance_sq = np.sum(diff * diff, axis=2)\n",
    "            range_kernel = np.exp(-color_distance_sq / (2 * sigma_color * sigma_color))\n",
    "            weights = spatial_kernel * range_kernel\n",
    "            weights_sum = np.sum(weights)\n",
    "            filtered[i, j, :] = np.sum(region * weights[:, :, None], axis=(0, 1)) / weights_sum\n",
    "\n",
    "    return filtered.astype(np.uint8)\n",
    "\n",
    "def preprocess_image(image_path, output_path, standard_size=(800, 600), d=9, sigma_color=75, sigma_space=75):\n",
    "    \"\"\"Preprocess the image and save it to the output path.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Warning: Unable to read image at {image_path}\")\n",
    "        return\n",
    "\n",
    "    resized_image = cv2.resize(image, standard_size)\n",
    "    lab_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2LAB)\n",
    "    L, A, B = cv2.split(lab_image)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    L_clahe = clahe.apply(L)\n",
    "    lab_clahe = cv2.merge((L_clahe, A, B))\n",
    "    enhanced_bgr = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "    preprocessed_image = my_bilateral_filter(enhanced_bgr, d, sigma_color, sigma_space)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    cv2.imwrite(output_path, preprocessed_image)\n",
    "    print(f\"Processed image saved to {output_path}\")\n",
    "\n",
    "def preprocess_dataset(input_dir, output_dir):\n",
    "    \"\"\"Preprocess all images in the dataset and maintain folder structure.\"\"\"\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist.\")\n",
    "        return\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                input_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(input_path, input_dir)\n",
    "                output_path = os.path.join(output_dir, relative_path)\n",
    "                preprocess_image(input_path, output_path)\n",
    "\n",
    "input_directory = 'smallerrefined'\n",
    "output_directory = 'postprocessing_datasettttt_degree0'\n",
    "preprocess_dataset(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
